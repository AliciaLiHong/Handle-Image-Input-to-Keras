{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1, Single image input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1, Loads an image into PIL format.\n",
    "2, Converts a PIL Image instance to a Numpy array.\n",
    "3, Expand the shape of the image array. In the example below, expand_dims convert shape(224,224,3) to shape(0,224,224,3). This is needed because the shape of input to model ResNet50 should be (None, 224,224,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "img_path = './elephant.jpg'  # image path   \n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)        #(224,224,3)\n",
    "x = np.expand_dims(x, axis=0)      #(0,224,224,3)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "model = ResNet50(weights='imagenet')\n",
    "preds = model.predict(x)\n",
    "# decode the results into a list of tuples (class, description, probability)\n",
    "# (one such list for each sample in the batch)\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2, Multiple images input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two ways to implement the multiple images input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Using glob -- a direct method\n",
    "Firstly, use glob to do pathname pattern expansion.\n",
    "Then, use for loop to load images in the same file.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "import glob\n",
    "\n",
    "file_path = './images/'\n",
    "f_names = glob.glob(file_path + '*.jpg') #list\n",
    "\n",
    "imgs = []\n",
    "for i in range(len(f_names)):\n",
    "    img = image.load_img(f_names[i], target_size = (224, 224))\n",
    "    arr_img = image.img_to_array(img)\n",
    "    arr_img = np.expand_dims(arr_img, axis=0)\n",
    "    imgs.append(arr_img)\n",
    "\n",
    "x = np.concatenate([x for x in imgs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Generate a csv -- not a direct method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from os import listdir, makedirs\n",
    "from os.path import join, exists, expanduser\n",
    "from tqdm import tqdm\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import xception\n",
    "\n",
    "\n",
    "# function to convert image to array\n",
    "def read_img(address, size):\n",
    "    \"\"\"Read and resize image.\n",
    "    Returns Image as numpy array, by normalizing the values\n",
    "    \"\"\"\n",
    "    img = image.load_img(address, target_size=size)\n",
    "    img = image.img_to_array(img)\n",
    "    return img\n",
    "\n",
    "# function to convert labels to one hot encoding vector\n",
    "def OneHotEncoded(y_train):\n",
    "    y_t=np.zeros((len(y_train),Num_Class), dtype=int)\n",
    "    for i,x in enumerate(y_train):\n",
    "        y_t[i][int(x)]=1\n",
    "    return y_t\n",
    "\n",
    "import os\n",
    "import csv\n",
    "from shutil import copy2\n",
    "directory_lists=os.listdir(\"./images/train\")\n",
    "labels = {}\n",
    "data = {}\n",
    "\n",
    "with open('./labels.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['id','class'])\n",
    "    for i in range(0, len(directory_lists)):                        #'''directory_lists == files in /train == ['c0', 'c1', ... , 'c9']'''\n",
    "        t = directory_lists[i][1:]\n",
    "        imag=os.listdir(\"./images/train/\"+str(directory_lists[i]))     #'''imag == files in /train/c# '''\n",
    "        current_loc = \"./images/train/\"+str(directory_lists[i])+\"/\"    #'''./imgs/train/c#/'''\n",
    "        for k in range(0, len(imag)):\n",
    "            x=[current_loc+str(imag[k])]+[t]\n",
    "            writer.writerow(x)\n",
    "\n",
    "data_dir = './'\n",
    "labels = pd.read_csv(join(data_dir, 'labels.csv'))\n",
    "\n",
    "INPUT_SIZE = 299\n",
    "POOLING = 'avg'\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "x_train = np.zeros((len(labels), INPUT_SIZE, INPUT_SIZE, 3), dtype='float32')\n",
    "y_train= np.zeros((len(labels),), dtype='float32')\n",
    "\n",
    "for i, img_id in tqdm(enumerate(labels['id'])):\n",
    "    img = read_img(img_id, (INPUT_SIZE, INPUT_SIZE))\n",
    "    x = xception.preprocess_input(np.expand_dims(img.copy(), axis=0))\n",
    "    x_train[i] = x\n",
    "    y_train[i]=int(labels['class'][i])\n",
    "print('Train Images shape: {} size: {:,}'.format(x_train.shape, x_train.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Using generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'images/train',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=1,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'images/validation',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=1,\n",
    "        class_mode='binary')\n",
    "\n",
    "model = ResNet50(weights = 'imagenet')\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
